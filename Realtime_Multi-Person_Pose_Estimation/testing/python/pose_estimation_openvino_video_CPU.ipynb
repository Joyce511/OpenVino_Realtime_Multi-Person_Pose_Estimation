{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IEPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import PIL.Image\n",
    "import math\n",
    "#import caffe\n",
    "from config_reader import config_reader\n",
    "import util\n",
    "import copy\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "from numpy import ma\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param, model = config_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xml = \"/home/yue/Realtime_Multi-Person_Pose_Estimation/model/_trained_COCO/pose_iter_440000.xml\"\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "prob_threshold = 0.5\n",
    "labels_map = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing plugin for CPU device...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing plugin for CPU device...\")\n",
    "plugin = IEPlugin(device=\"CPU\", plugin_dirs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding CPU extenstions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding CPU extenstions...\")\n",
    "plugin.add_cpu_extension(\"/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/libcpu_extension_sse4.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading IR...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading IR...\")\n",
    "net = IENetwork.from_ir(model=model_xml, weights=model_bin)\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IR to the plugin...\n",
      "(1, 3, 368, 368)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading IR to the plugin...\")\n",
    "exec_net = plugin.load(network=net, num_requests=2)\n",
    "# Read and pre-process input image\n",
    "n, c, h, w = net.inputs[input_blob]\n",
    "print((n,c,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference in async mode...\n"
     ]
    }
   ],
   "source": [
    "#input_stream = \"../sample_video/dance.mp4\"\n",
    "input_stream = \"../sample_video/solo_dance.mp4\"\n",
    "cap = cv.VideoCapture(input_stream)\n",
    "cur_request_id = 0\n",
    "next_request_id = 1\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "    \n",
    "print(\"Starting inference in async mode...\")\n",
    "\n",
    "render_time = 0\n",
    "total_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find connection in the specified sequence, center 29 is in the position 15\n",
    "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "# the middle joints heatmap correpondence\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22], \\\n",
    "          [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], \\\n",
    "          [55,56], [37,38], [45,46]]\n",
    "colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "fps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "        total_start = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        initial_w = cap.get(3)\n",
    "        initial_h = cap.get(4)\n",
    "        \n",
    "        image = cv.resize(frame, (w, h))\n",
    "\n",
    "        image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "        image = image.reshape((1,3,368,368))/256 - 0.5\n",
    "        img_show = frame;\n",
    "        # Main sync point:\n",
    "        # in the truly Async mode we start the NEXT infer request, while waiting for the CURRENT to complete\n",
    "        # in the regular mode we start the CURRENT request and immediately wait for it's completion\n",
    "        inf_start = time.time()\n",
    "        res = exec_net.infer(inputs={input_blob: image})\n",
    "        det_time = time.time() - inf_start\n",
    "\n",
    "        # Parse detection results of the current request\n",
    "        res_heatMap = res['Mconv7_stage6_L2']\n",
    "        res_paf = res['Mconv7_stage6_L1']\n",
    "\n",
    "        #Process outputs\n",
    "        res_heatMap = np.squeeze(res_heatMap, axis=0)\n",
    "        res_paf = np.squeeze(res_paf, axis=0)\n",
    "\n",
    "        # extract outputs, resize, and remove padding\n",
    "        heatmap = np.transpose(res_heatMap, (1,2,0)) # output 1 is heatmaps\n",
    "\n",
    "        heatmap = cv.resize(heatmap, (frame.shape[1], frame.shape[0]), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "        paf = np.transpose(res_paf, (1,2,0)) # output 0 is PAFs\n",
    "\n",
    "        paf = cv.resize(paf, (frame.shape[1], frame.shape[0]), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "        heatmap_avg = heatmap \n",
    "        paf_avg = paf \n",
    "\n",
    "\n",
    "        U = paf_avg[:,:,16] * -1\n",
    "        V = paf_avg[:,:,17]\n",
    "        X, Y = np.meshgrid(np.arange(U.shape[1]), np.arange(U.shape[0]))\n",
    "        M = np.zeros(U.shape, dtype='bool')\n",
    "        M[U**2 + V**2 < 0.5 * 0.5] = True\n",
    "        U = ma.masked_array(U, mask=M)\n",
    "        V = ma.masked_array(V, mask=M)\n",
    "\n",
    "        all_peaks = []\n",
    "        peak_counter = 0\n",
    "\n",
    "        for part in range(19-1):\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            map_ori = heatmap_avg[:,:,part]\n",
    "            map = gaussian_filter(map_ori, sigma=3)\n",
    "\n",
    "            map_left = np.zeros(map.shape)\n",
    "            map_left[1:,:] = map[:-1,:]\n",
    "            map_right = np.zeros(map.shape)\n",
    "            map_right[:-1,:] = map[1:,:]\n",
    "            map_up = np.zeros(map.shape)\n",
    "            map_up[:,1:] = map[:,:-1]\n",
    "            map_down = np.zeros(map.shape)\n",
    "            map_down[:,:-1] = map[:,1:]\n",
    "\n",
    "            peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > param['thre1']))\n",
    "            peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0])) # note reverse\n",
    "            peaks_with_score = [x + (map_ori[x[1],x[0]],) for x in peaks]\n",
    "            id = range(peak_counter, peak_counter + len(peaks))\n",
    "            peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
    "\n",
    "            all_peaks.append(peaks_with_score_and_id)\n",
    "            peak_counter += len(peaks)\n",
    "\n",
    "\n",
    "        connection_all = []\n",
    "        special_k = []\n",
    "        mid_num = 10\n",
    "\n",
    "        for k in range(len(mapIdx)):\n",
    "            score_mid = paf_avg[:,:,[x-19 for x in mapIdx[k]]]\n",
    "            candA = all_peaks[limbSeq[k][0]-1]\n",
    "            candB = all_peaks[limbSeq[k][1]-1]\n",
    "            nA = len(candA)\n",
    "            nB = len(candB)\n",
    "            indexA, indexB = limbSeq[k]\n",
    "            if(nA != 0 and nB != 0):\n",
    "                connection_candidate = []\n",
    "                for i in range(nA):\n",
    "                    for j in range(nB):\n",
    "                        vec = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                        norm = math.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
    "                        vec = np.divide(vec, norm)\n",
    "\n",
    "                        startend = list(zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), \\\n",
    "                                       np.linspace(candA[i][1], candB[j][1], num=mid_num)))\n",
    "\n",
    "                        vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] \\\n",
    "                                          for I in range(len(startend))])\n",
    "                        vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] \\\n",
    "                                          for I in range(len(startend))])\n",
    "                        score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                        score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*frame.shape[0]/norm-1, 0)\n",
    "                        criterion1 = len(np.nonzero(score_midpts > param['thre2'])[0]) > 0.8 * len(score_midpts)\n",
    "                        criterion2 = score_with_dist_prior > 0\n",
    "                        if criterion1 and criterion2:\n",
    "                            connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
    "\n",
    "                connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "                connection = np.zeros((0,5))\n",
    "                for c in range(len(connection_candidate)):\n",
    "                    i,j,s = connection_candidate[c][0:3]\n",
    "                    if(i not in connection[:,3] and j not in connection[:,4]):\n",
    "                        connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
    "                        if(len(connection) >= min(nA, nB)):\n",
    "                            break\n",
    "\n",
    "                connection_all.append(connection)\n",
    "            else:\n",
    "                special_k.append(k)\n",
    "                connection_all.append([])\n",
    "        # last number in each row is the total parts number of that person\n",
    "        # the second last number in each row is the score of the overall configuration\n",
    "        subset = -1 * np.ones((0, 20))\n",
    "        candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "        for k in range(len(mapIdx)):\n",
    "            if k not in special_k:\n",
    "                partAs = connection_all[k][:,0]\n",
    "                partBs = connection_all[k][:,1]\n",
    "                indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "\n",
    "                for i in range(len(connection_all[k])): #= 1:size(temp,1)\n",
    "                    found = 0\n",
    "                    subset_idx = [-1, -1]\n",
    "                    for j in range(len(subset)): #1:size(subset,1):\n",
    "                        if subset[j][indexA] == partAs[i] or subset[j][indexB] == partBs[i]:\n",
    "                            subset_idx[found] = j\n",
    "                            found += 1\n",
    "\n",
    "                    if found == 1:\n",
    "                        j = subset_idx[0]\n",
    "                        if(subset[j][indexB] != partBs[i]):\n",
    "                            subset[j][indexB] = partBs[i]\n",
    "                            subset[j][-1] += 1\n",
    "                            subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "                    elif found == 2: # if found 2 and disjoint, merge them\n",
    "                        j1, j2 = subset_idx\n",
    "                        #print (\"found = 2\")\n",
    "                        membership = ((subset[j1]>=0).astype(int) + (subset[j2]>=0).astype(int))[:-2]\n",
    "                        if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
    "                            subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                            subset[j1][-2:] += subset[j2][-2:]\n",
    "                            subset[j1][-2] += connection_all[k][i][2]\n",
    "                            subset = np.delete(subset, j2, 0)\n",
    "                        else: # as like found == 1\n",
    "                            subset[j1][indexB] = partBs[i]\n",
    "                            subset[j1][-1] += 1\n",
    "                            subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "\n",
    "                    # if find no partA in the subset, create a new subset\n",
    "                    elif not found and k < 17:\n",
    "                        row = -1 * np.ones(20)\n",
    "                        row[indexA] = partAs[i]\n",
    "                        row[indexB] = partBs[i]\n",
    "                        row[-1] = 2\n",
    "                        row[-2] = sum(candidate[connection_all[k][i,:2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                        subset = np.vstack([subset, row])\n",
    "        deleteIdx = [];\n",
    "        for i in range(len(subset)):\n",
    "            if subset[i][-1] < 4 or subset[i][-2]/subset[i][-1] < 0.4:\n",
    "                deleteIdx.append(i)\n",
    "        subset = np.delete(subset, deleteIdx, axis=0)\n",
    "\n",
    "\n",
    "        stickwidth = 2\n",
    "        cmap = matplotlib.cm.get_cmap('hsv')\n",
    "\n",
    "        for i in range(18):\n",
    "            rgba = np.array(cmap(1 - i/18. - 1./36))\n",
    "            rgba[0:3] *= 255\n",
    "            for j in range(len(all_peaks[i])):\n",
    "                cv.circle(img_show, all_peaks[i][j][0:2], 4, colors[i], thickness=-1)\n",
    "\n",
    "        to_plot = cv.addWeighted(frame, 0.3, img_show, 0.7, 0)\n",
    "\n",
    "        for i in range(17):\n",
    "            for n in range(len(subset)):\n",
    "                index = subset[n][np.array(limbSeq[i])-1]\n",
    "                if -1 in index:\n",
    "                    continue\n",
    "                cur_canvas = img_show.copy()\n",
    "                Y = candidate[index.astype(int), 0]\n",
    "                X = candidate[index.astype(int), 1]\n",
    "                mX = np.mean(X)\n",
    "                mY = np.mean(Y)\n",
    "                length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "                angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "                polygon = cv.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "                cv.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "                img_show = cv.addWeighted(img_show, 0.4, cur_canvas, 0.6, 0)\n",
    "\n",
    "\n",
    "        #################################################################################################################\n",
    "        # Draw performance stats\n",
    "\n",
    "        inf_time_message = \"Inference time: {:.3f} ms\".format(det_time * 1000)\n",
    "        render_time_message = \"OpenCV rendering time: {:.3f} ms\".format(render_time * 1000)\n",
    "        total_time_message = \"Total Time Taken per Frame: {:.3f} ms\".format(total_time * 1000)\n",
    "        fps_message = \"FPS: {:.1f}\".format(fps);\n",
    "\n",
    "        cv.putText(img_show, inf_time_message, (15, 15), cv.FONT_HERSHEY_COMPLEX, 0.5, (200, 10, 10), 1)\n",
    "        cv.putText(img_show, render_time_message, (15, 30), cv.FONT_HERSHEY_COMPLEX, 0.5, (10, 10, 200), 1)\n",
    "        cv.putText(img_show, total_time_message, (15, 45), cv.FONT_HERSHEY_COMPLEX, 0.5, (10, 10, 200), 1)\n",
    "        cv.putText(img_show, fps_message, (15, 60), cv.FONT_HERSHEY_COMPLEX, 0.5, (10, 10, 200), 1)\n",
    "        \n",
    "        \n",
    "        #img_show = img_show[:,:,[2,1,0]]\n",
    "        render_start = time.time()\n",
    "        cv.imshow(\"Detection Results\", img_show)\n",
    "        \n",
    "        #plt.imshow(img_show)\n",
    "        \n",
    "        render_end = time.time()\n",
    "        render_time = render_end - render_start\n",
    "        total_time = render_end - total_start\n",
    "        \n",
    "        fps = float((1/total_time))\n",
    "        \n",
    "        key = cv.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "            \n",
    "cv.destroyAllWindows()\n",
    "del exec_net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
